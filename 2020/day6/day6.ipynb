{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 6 - Customs Declarations\n",
    "\n",
    "This feels fairly easy at first glance, this is all about building sets.  Again, we are after seperating the input by blank lines, which was a bit of a pain back in a few earlier days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipytest\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [line.strip() for line in open(\"day6.txt\").readlines()]\n",
    "lines2 = [\"$$\" if (line == \"\") else line for line in lines]\n",
    "lines3 = \"\".join(lines2).split('$$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By joining all the lines together, we're loosing individual answers, but we probably don't care, since we are considering people as groups instead.\n",
    "\n",
    "So now all we need to do is turn the line into a set, which will discard dup0licates and then count the lengths of teh sets, and sum them all..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6885"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(set(l)) for l in lines3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "Darn it, I knew I needed to keep track of individuals.  In this case we're going to need to parse a bit better.\n",
    "The basic premise is similar, but now we need produce a set per group, that set will be the intersection of all of the sets of answers.  Then we can simply count the sets again...\n",
    "\n",
    "So if we had rewritten the previous version as:\n",
    "\n",
    "`\n",
    "groups = [set(l) for l in lines3]\n",
    "sum = sum([len(group) for group in groups]`\n",
    "\n",
    "It would be clear that the only real difference here is that our groups assignment is more complex..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3550"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = [line.strip() for line in open(\"day6.txt\").readlines()] + [\"\"]\n",
    "# We now have each group ending in a single \"\"\n",
    "\n",
    "groups = []\n",
    "group = None\n",
    "for line in lines:\n",
    "    if line == \"\":\n",
    "        groups.append(group)\n",
    "        group = None\n",
    "    else:\n",
    "        if group == None:\n",
    "            group = set(line)\n",
    "        else:\n",
    "            group &= set(line)\n",
    "\n",
    "sum([len(group) for group in groups])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactoring and making nicer\n",
    "\n",
    "Ok, I did this in record time, so I wonder if I can make this a bit cleaner, with code that based on the previous 6 days, I might need to reuse.\n",
    "\n",
    "### Part 1 - Inputs in groups\n",
    "We've had several inputs now where it's multiple lines, separated by an empty line.  My current solution is both nasty, uses a weird sentinel, and loses the line breaks, which often have meaning.  Let's do something better that can take the following input:\n",
    "`abc\n",
    "de\n",
    "\n",
    "acd\n",
    "d\n",
    "\n",
    "a\n",
    "a\n",
    "a`\n",
    "\n",
    "and turn it into\n",
    "`[\n",
    "['abc', 'de'],\n",
    "['acd', 'd],\n",
    "['a', 'a', 'a']\n",
    "]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_groups(lines):\n",
    "    result = []\n",
    "    group = []\n",
    "    for line in lines:\n",
    "        if line == \"\":\n",
    "            result.append(group)\n",
    "            group = []\n",
    "        else:\n",
    "            group.append(line)\n",
    "    result.append(group)\n",
    "    return result\n",
    "\n",
    "assert [['a', 'b']] == parse_groups([\"a\", \"b\"])\n",
    "assert [['a', 'b'], ['c']] == parse_groups(['a', 'b', '', 'c'])\n",
    "\n",
    "def parse_groups_from_file(filename):\n",
    "    return parse_groups([l.strip() for l in open(filename)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can refactor our answers for 1 and 2. \n",
    "\n",
    "Additionally, I didn't like the special code to handle the first line in the set, so I'm going to try using what is effectively the infinite set, for our input at least"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6885\n",
      "3550\n"
     ]
    }
   ],
   "source": [
    "groups = parse_groups_from_file('day6.txt')\n",
    "groupsets = [set(\"\".join(l)) for l in groups]\n",
    "print(sum([len(group) for group in groupsets]))\n",
    "\n",
    "group_intersections = []\n",
    "for group in groups:\n",
    "    groupset = set(\"abcdefghijklmnopqrstuvwxyz\")\n",
    "    for person in group:\n",
    "        groupset &= set(person)\n",
    "    group_intersections.append(groupset)\n",
    "print(sum([len(group) for group in group_intersections]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's much nicer for part 2, but that looks an awful lot like a reduce function on each set, I wonder if functools can make that even clearer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3550\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "infiniteset = set(\"abcdefghijklmnopqrstuvwxyz\")\n",
    "group_intersections = [functools.reduce(lambda accumulator,person: accumulator & set(person), group, infiniteset) for group in groups]\n",
    "print(sum([len(group) for group in group_intersections]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go.  I'm not actually sure how much clearer that is, the lambda somewhat loses the fact that the groups are lists of lists, and that we're turning each person in the group into a set, and then intersecting the sets.  But it works, and is much fewer lines of code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
